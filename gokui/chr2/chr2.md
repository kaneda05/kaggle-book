## 第2章 探索的データ分析とモデルの作成・検証・性能向上

[PyTorchによる実装例](https://github.com/kaneda05/kaggle-book/blob/main/gokui/chr2/1.ipynb)

[ミニバッチ学習の実装](https://github.com/kaneda05/kaggle-book/blob/main/gokui/chr2/2.ipynb)

モデルの検証
- [ホールドアウト法(holdout validation)](https://github.com/kaneda05/kaggle-book/blob/main/gokui/chr2/3.ipynb)
- [交差検証法](https://github.com/kaneda05/kaggle-book/blob/main/gokui/chr2/4.ipynb)
- [Stratified K-Fold](https://github.com/kaneda05/kaggle-book/blob/main/gokui/chr2/5.ipynb)


参考になりそうな記事
- [PyTorchでクロスバリデーション](https://qiita.com/ground0state/items/ad879a84bf946ef94da8)


### 学習メモ

- group k-fold
データセット
[state-farm-distracted-driver-detection](https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/overview)

- stratified froup k-fold
データセット
[PetFinder.my Adoption Prediction](https://www.kaggle.com/competitions/petfinder-adoption-prediction)

- multilavel stratified k-fold
データセット
[Mechanisms of Action (MoA) Prediction](https://www.kaggle.com/competitions/lish-moa)

- time series split
データセット
[Recruit Restaurant Visitor Forecasting](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting)